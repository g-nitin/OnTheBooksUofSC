{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Preferred notebook for model creation with 100 trials; also used for label prediction (Feb, 2024)\n",
    "- #### Morgan / Taylor's labeled sentences added in this version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This file creates model with MORE labelled data (Coded Sentences Drawn from Civic Center's Research and Taylor (1892_labeled_sentences.csv). Renamed \"Label\" column to \"jim_crow\".\n",
    "- Added 11 updated files with correct splitting and coded by Axton : 1868_24-25_updated, 1868_143-145_updated, 1868_146-151_updated, 1877_571-586_updated.csv, 1884_24-26_updated.csv, 1886-87_1031-1034_updated.csv, 1886-87_1072-1074_updated.csv,1868_24-25_updated, 1896_63act_updated, 1907_518-522_updated, 1925_324act_updated, shared_base_training_set_v2.csv (from UNC)\n",
    "- Converted the excel files coded by Axton to csv\n",
    "- Renamed the above files to make the naming consistent (- replaced by _, added 'labeled_sentences')\n",
    "- Renamed the column 'Coding (Axton)\" of Civic Center data to 'jim_crow' , 'Act' to 'sentence' and 'Year' to 'year' for consistency\n",
    "- Added column state = 'South Carolina' in all Civic Center coded files\n",
    "- Replaced the 'year' values in file 1886_87_1031-1034.csv from '1886-87' to 1886 and '1868_146-151_updated.csv' from '1868-69' to 1868\n",
    "- Changed case in some column names (upper to lower)\n",
    "- Read \"UNC_shared_base_training_set_v2.csv\" file differently to perform some filteration as mentioned by Matthew Jansen (UNC) \n",
    "- CASE 1: Training and testing model on combined data of UNC and USC\n",
    "- CASE 2: Training model on UNC data and testing model on USC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Used SMOTEN to rebalance the imbalanced dataset and removed stopwords but the model performance did not improve in comparison to without SMOTEN/stopword removal.**\n",
    "- **The time taken to create the model is very less than the time taken without SMOTEN/stopwords removal.**\n",
    "- **This code also predicts labels for the WHOLE CORPUS and for EACH YEAR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: Training and testing model on both USC and UNC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/vandana/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# data reading libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "#Saving model so that we don't have to run it every time we open this notebook\n",
    "import pickle \n",
    "\n",
    "# Text Libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords') \n",
    "\n",
    "# Machine Learning Libraries\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Model Tuning Libraries\n",
    "from hyperopt import hp, tpe, space_eval, Trials\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "#Evaluation Libraries\n",
    "from sklearn.metrics import confusion_matrix, classification_report, make_scorer, f1_score\n",
    "\n",
    "#Visualization libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Supression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data and store in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read data from the folder \"LabeledData\". Since one file \"UNC_shared_base_training_set_v2.csv\" is different from others, we are \n",
    "# reading it separately from others.\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "for file in Path(\"LabeledData_UNC_USC_Feb2024\").glob('*.csv'):\n",
    "    if str(file).find(\"base\") != -1 :\n",
    "        df1 = pd.read_csv(file)       # reading the \"UNC_shared_base_training_set_v2.csv\" file and store it in dataframe df1\n",
    "    else: \n",
    "        df = pd.read_csv(file, usecols=['year', 'state','sentence', 'jim_crow'])\n",
    "        new_df = new_df.append(df, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_section_id</th>\n",
       "      <th>source</th>\n",
       "      <th>law_type</th>\n",
       "      <th>UNC_training</th>\n",
       "      <th>state</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section_sents</th>\n",
       "      <th>char_len</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>jim_crow</th>\n",
       "      <th>jim_crow_type</th>\n",
       "      <th>year</th>\n",
       "      <th>corpus_sentence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1947_session laws_979_2</td>\n",
       "      <td>murray</td>\n",
       "      <td>session laws</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>Subject only to restrictions and conditions no...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>explicit</td>\n",
       "      <td>1947</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1935_public laws_423_3</td>\n",
       "      <td>murray</td>\n",
       "      <td>public laws</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>Powers and duties of Commission.</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Axton</td>\n",
       "      <td>0</td>\n",
       "      <td>explicit</td>\n",
       "      <td>1935</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1935_public laws_423_3</td>\n",
       "      <td>murray</td>\n",
       "      <td>public laws</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>The said Textbook Purchase and Rental Commissi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>Axton</td>\n",
       "      <td>0</td>\n",
       "      <td>explicit</td>\n",
       "      <td>1935</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1935_public laws_423_3</td>\n",
       "      <td>murray</td>\n",
       "      <td>public laws</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>Acquire by contract, and/or purchase, such tex...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Axton</td>\n",
       "      <td>0</td>\n",
       "      <td>explicit</td>\n",
       "      <td>1935</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1935_public laws_423_3</td>\n",
       "      <td>murray</td>\n",
       "      <td>public laws</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>and instructional supplies, which are, or may ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>Axton</td>\n",
       "      <td>0</td>\n",
       "      <td>explicit</td>\n",
       "      <td>1935</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         corpus_section_id  source      law_type  UNC_training  \\\n",
       "0  1947_session laws_979_2  murray  session laws           1.0   \n",
       "1   1935_public laws_423_3  murray   public laws           1.0   \n",
       "2   1935_public laws_423_3  murray   public laws           1.0   \n",
       "3   1935_public laws_423_3  murray   public laws           1.0   \n",
       "4   1935_public laws_423_3  murray   public laws           1.0   \n",
       "\n",
       "            state                                           sentence  \\\n",
       "0  NORTH CAROLINA  Subject only to restrictions and conditions no...   \n",
       "1  NORTH CAROLINA                   Powers and duties of Commission.   \n",
       "2  NORTH CAROLINA  The said Textbook Purchase and Rental Commissi...   \n",
       "3  NORTH CAROLINA  Acquire by contract, and/or purchase, such tex...   \n",
       "4  NORTH CAROLINA  and instructional supplies, which are, or may ...   \n",
       "\n",
       "   section_sents  char_len reviewer  jim_crow jim_crow_type  year  \\\n",
       "0            1.0     779.0      NaN         1      explicit  1947   \n",
       "1           10.0      32.0    Axton         0      explicit  1935   \n",
       "2           10.0     146.0    Axton         0      explicit  1935   \n",
       "3           10.0      53.0    Axton         0      explicit  1935   \n",
       "4           10.0     218.0    Axton         0      explicit  1935   \n",
       "\n",
       "  corpus_sentence_id  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read first 5 rows of \"UNC_shared_base_training_set_v2.csv\" file whose columns are different from other csv files\n",
    "df1[['jim_crow']] = df1[['jim_crow']].astype(int) # Change the datatype of jim_crow\" to int in df1 (it is 0.0, 1.0, 2.0 currently)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10231"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find length of df1\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only select rows which have a 'jim_crow' value of either 0 or 1\n",
    "df.loc[df.jim_crow.isin([0,1]), :]\n",
    "\n",
    "#### Only select rows which have a 'jim_crow_type' value of 'extrinsic' or 'implicit'\n",
    "df.loc[df.jim_crow_type.isin([\"extrinsic\",\"implicit\"]), :]\n",
    "\n",
    "#### Only select rows which DONT have a 'jim_crow_type' value of 'extrinsic' or 'implicit' by using '~'\n",
    "df.loc[~df.jim_crow_type.isin([\"extrinsic\",\"implicit\"]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_section_id</th>\n",
       "      <th>source</th>\n",
       "      <th>law_type</th>\n",
       "      <th>UNC_training</th>\n",
       "      <th>state</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section_sents</th>\n",
       "      <th>char_len</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>jim_crow</th>\n",
       "      <th>jim_crow_type</th>\n",
       "      <th>year</th>\n",
       "      <th>corpus_sentence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1947_session laws_979_2</td>\n",
       "      <td>murray</td>\n",
       "      <td>session laws</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>Subject only to restrictions and conditions no...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>explicit</td>\n",
       "      <td>1947</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1935_public laws_423_3</td>\n",
       "      <td>murray</td>\n",
       "      <td>public laws</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>Powers and duties of Commission.</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Axton</td>\n",
       "      <td>0</td>\n",
       "      <td>explicit</td>\n",
       "      <td>1935</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1935_public laws_423_3</td>\n",
       "      <td>murray</td>\n",
       "      <td>public laws</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>The said Textbook Purchase and Rental Commissi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>Axton</td>\n",
       "      <td>0</td>\n",
       "      <td>explicit</td>\n",
       "      <td>1935</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1935_public laws_423_3</td>\n",
       "      <td>murray</td>\n",
       "      <td>public laws</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>Acquire by contract, and/or purchase, such tex...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Axton</td>\n",
       "      <td>0</td>\n",
       "      <td>explicit</td>\n",
       "      <td>1935</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1935_public laws_423_3</td>\n",
       "      <td>murray</td>\n",
       "      <td>public laws</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>and instructional supplies, which are, or may ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>Axton</td>\n",
       "      <td>0</td>\n",
       "      <td>explicit</td>\n",
       "      <td>1935</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         corpus_section_id  source      law_type  UNC_training  \\\n",
       "0  1947_session laws_979_2  murray  session laws           1.0   \n",
       "1   1935_public laws_423_3  murray   public laws           1.0   \n",
       "2   1935_public laws_423_3  murray   public laws           1.0   \n",
       "3   1935_public laws_423_3  murray   public laws           1.0   \n",
       "4   1935_public laws_423_3  murray   public laws           1.0   \n",
       "\n",
       "            state                                           sentence  \\\n",
       "0  NORTH CAROLINA  Subject only to restrictions and conditions no...   \n",
       "1  NORTH CAROLINA                   Powers and duties of Commission.   \n",
       "2  NORTH CAROLINA  The said Textbook Purchase and Rental Commissi...   \n",
       "3  NORTH CAROLINA  Acquire by contract, and/or purchase, such tex...   \n",
       "4  NORTH CAROLINA  and instructional supplies, which are, or may ...   \n",
       "\n",
       "   section_sents  char_len reviewer  jim_crow jim_crow_type  year  \\\n",
       "0            1.0     779.0      NaN         1      explicit  1947   \n",
       "1           10.0      32.0    Axton         0      explicit  1935   \n",
       "2           10.0     146.0    Axton         0      explicit  1935   \n",
       "3           10.0      53.0    Axton         0      explicit  1935   \n",
       "4           10.0     218.0    Axton         0      explicit  1935   \n",
       "\n",
       "  corpus_sentence_id  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only select those rows which have value of either 0 or 1 in \"jim_crow\" column AND do not have value of \"extrinsic\" or \n",
    "# \"intrinsic\" in \"jim_crow_type\" column ---- as suggested by Matt Jansen (UNC)\n",
    "df1_good = df1.loc[(df1.jim_crow.isin([0,1])) & (~df1.jim_crow_type.isin([\"extrinsic\",\"implicit\"])),:].copy()\n",
    "df1_good.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>sentence</th>\n",
       "      <th>jim_crow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1947</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>Subject only to restrictions and conditions no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1935</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>Powers and duties of Commission.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1935</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>The said Textbook Purchase and Rental Commissi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1935</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>Acquire by contract, and/or purchase, such tex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1935</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>and instructional supplies, which are, or may ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10225</th>\n",
       "      <td>1909</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>On behalf of the general welfare of the city o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10226</th>\n",
       "      <td>1895</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>The clerk of the commissioners, on or before t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10228</th>\n",
       "      <td>1899</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>The township school trustees shall divide thei...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10229</th>\n",
       "      <td>1899</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>They shall consult the convenience and necessi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10230</th>\n",
       "      <td>1901</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>That the Treasurer of Wilkes County be and he ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9492 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year           state  \\\n",
       "0      1947  NORTH CAROLINA   \n",
       "1      1935  NORTH CAROLINA   \n",
       "2      1935  NORTH CAROLINA   \n",
       "3      1935  NORTH CAROLINA   \n",
       "4      1935  NORTH CAROLINA   \n",
       "...     ...             ...   \n",
       "10225  1909  NORTH CAROLINA   \n",
       "10226  1895  NORTH CAROLINA   \n",
       "10228  1899  NORTH CAROLINA   \n",
       "10229  1899  NORTH CAROLINA   \n",
       "10230  1901  NORTH CAROLINA   \n",
       "\n",
       "                                                sentence  jim_crow  \n",
       "0      Subject only to restrictions and conditions no...         1  \n",
       "1                       Powers and duties of Commission.         0  \n",
       "2      The said Textbook Purchase and Rental Commissi...         0  \n",
       "3      Acquire by contract, and/or purchase, such tex...         0  \n",
       "4      and instructional supplies, which are, or may ...         0  \n",
       "...                                                  ...       ...  \n",
       "10225  On behalf of the general welfare of the city o...         0  \n",
       "10226  The clerk of the commissioners, on or before t...         1  \n",
       "10228  The township school trustees shall divide thei...         0  \n",
       "10229  They shall consult the convenience and necessi...         1  \n",
       "10230  That the Treasurer of Wilkes County be and he ...         1  \n",
       "\n",
       "[9492 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe from df1_good that has columns same as new_df\n",
    "new_df1 = df1_good[['year', 'state', 'sentence', 'jim_crow']]\n",
    "new_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Cleaning and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>sentence</th>\n",
       "      <th>jim_crow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1896</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>it shall be the duty of each county treasurer ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1896</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>all moneys disbursed by any county treasurer o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1896</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>each county treasurer shall make out and forwa...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1896</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>the county treasurer shall carry forward all s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1896</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>it shall be unlawful for any county treasurer,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year           state                                           sentence  \\\n",
       "0  1896  SOUTH CAROLINA  it shall be the duty of each county treasurer ...   \n",
       "1  1896  SOUTH CAROLINA  all moneys disbursed by any county treasurer o...   \n",
       "2  1896  SOUTH CAROLINA  each county treasurer shall make out and forwa...   \n",
       "3  1896  SOUTH CAROLINA  the county treasurer shall carry forward all s...   \n",
       "4  1896  SOUTH CAROLINA  it shall be unlawful for any county treasurer,...   \n",
       "\n",
       "   jim_crow  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display first 5 rows of the data new_df\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>sentence</th>\n",
       "      <th>jim_crow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [year, state, sentence, jim_crow]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace '1886-87' in \"year\" column by 1886 and '1868-69' by 1868\n",
    "new_df.replace('1886-87', '1886', inplace=True)\n",
    "new_df.replace('1868-69', '1868', inplace=True)\n",
    "new_df[new_df['year'] == '1868-69'].head() # emplty dataframe because we have replaced \"1886-87\" by \"1886\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The length of new_df is 27072\n",
      " The length of new_df1 is 9492\n"
     ]
    }
   ],
   "source": [
    "# find the size of each dataframe\n",
    "print(\" The length of new_df is\", len(new_df))\n",
    "print(\" The length of new_df1 is\", len(new_df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13086\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check how many entries are null or empty in the two datasets\n",
    "print(new_df.isnull().sum().sum())\n",
    "print(new_df1.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove all the null entries - coming from the 3 files shared by Morgan/Taylor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "new_df_clean = new_df.dropna(subset=['jim_crow'])\n",
    "print(new_df_clean.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column datatypes of new_df_clean are below: \n",
      " year         object\n",
      "state        object\n",
      "sentence     object\n",
      "jim_crow    float64\n",
      "dtype: object\n",
      "Column datatypes of new_df1 are below: \n",
      " year         int64\n",
      "state       object\n",
      "sentence    object\n",
      "jim_crow     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# find the data types of columns of new_df1 and new_df\n",
    "print(\"Column datatypes of new_df_clean are below: \\n\", new_df_clean.dtypes)\n",
    "print(\"Column datatypes of new_df1 are below: \\n\", new_df1.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the data type of the two dataframes are SAME as we are going to append the datasets to create ONE large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the datatype of \"year\" and \"jim_crow\" to string in new_df1 \n",
    "#new_df1[['jim_crow']] = new_df1[['jim_crow']].astype(int)\n",
    "#new_df1[['year']] = new_df1[['year']].astype(str)\n",
    "\n",
    "# # Change the datatype of 'year' to string in new_df\n",
    "new_df_clean[['year']] = new_df_clean[['year']].astype(int)\n",
    "new_df_clean[['jim_crow']] = new_df_clean[['jim_crow']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column datatypes of new_df_clean are below: \n",
      " year         int64\n",
      "state       object\n",
      "sentence    object\n",
      "jim_crow     int64\n",
      "dtype: object\n",
      "Column datatypes of new_df1 are below: \n",
      " year         int64\n",
      "state       object\n",
      "sentence    object\n",
      "jim_crow     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# find the data types of columns of new_df1 and new_df after changing\n",
    "print(\"Column datatypes of new_df_clean are below: \\n\", new_df_clean.dtypes)\n",
    "print(\"Column datatypes of new_df1 are below: \\n\", new_df1.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1896, 1907, '1886', 1937, 1922, 1877, 1879, 1898, 1900, 1903, 1904,\n",
       "       1905, 1908, 1909, 1910, 1911, 1912, 1914, 1915, 1916, 1917, 1918,\n",
       "       1920, 1924, 1926, 1928, 1930, 1934, 1872, 1878, 1906, 1891, 1923,\n",
       "       1935, 1938, 1939, 1940, 1943, 1944, 1945, 1947, 1933, 1927, 1925,\n",
       "       1913, 1899, 1901, 1941, 1949, 1889, 1887, 1885, 1883, 1881, 1880,\n",
       "       1897, 1893, 1895, 1929, 1931, 1919, 1955, 1959, 1967, 1965, 1957,\n",
       "       1869, 1963, 1951, 1868, 1961, 1870, 1921, 1953, 1876, 1871, 1866,\n",
       "       1874, 1873, 1956, 1888, 1952, 1892, 1884, '1868'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.year.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append the 2 datasets to create a big labeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23479\n"
     ]
    }
   ],
   "source": [
    "# Create a large dataset with the 2 separate datasets\n",
    "combined_df = new_df_clean.append(new_df1,ignore_index = True)\n",
    "\n",
    "#find the length of combined dataset\n",
    "print(len(combined_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the combined data to csv file\n",
    "combined_df.to_csv(\"combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>sentence</th>\n",
       "      <th>jim_crow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1896</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>it shall be the duty of each county treasurer ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1896</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>all moneys disbursed by any county treasurer o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1896</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>each county treasurer shall make out and forwa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1896</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>the county treasurer shall carry forward all s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1896</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>it shall be unlawful for any county treasurer,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23474</th>\n",
       "      <td>1909</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>on behalf of the general welfare of the city o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23475</th>\n",
       "      <td>1895</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>the clerk of the commissioners, on or before t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23476</th>\n",
       "      <td>1899</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>the township school trustees shall divide thei...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23477</th>\n",
       "      <td>1899</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>they shall consult the convenience and necessi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23478</th>\n",
       "      <td>1901</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>that the treasurer of wilkes county be and he ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23479 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year           state  \\\n",
       "0      1896  SOUTH CAROLINA   \n",
       "1      1896  SOUTH CAROLINA   \n",
       "2      1896  SOUTH CAROLINA   \n",
       "3      1896  SOUTH CAROLINA   \n",
       "4      1896  SOUTH CAROLINA   \n",
       "...     ...             ...   \n",
       "23474  1909  NORTH CAROLINA   \n",
       "23475  1895  NORTH CAROLINA   \n",
       "23476  1899  NORTH CAROLINA   \n",
       "23477  1899  NORTH CAROLINA   \n",
       "23478  1901  NORTH CAROLINA   \n",
       "\n",
       "                                                sentence  jim_crow  \n",
       "0      it shall be the duty of each county treasurer ...         0  \n",
       "1      all moneys disbursed by any county treasurer o...         0  \n",
       "2      each county treasurer shall make out and forwa...         0  \n",
       "3      the county treasurer shall carry forward all s...         0  \n",
       "4      it shall be unlawful for any county treasurer,...         0  \n",
       "...                                                  ...       ...  \n",
       "23474  on behalf of the general welfare of the city o...         0  \n",
       "23475  the clerk of the commissioners, on or before t...         1  \n",
       "23476  the township school trustees shall divide thei...         0  \n",
       "23477  they shall consult the convenience and necessi...         1  \n",
       "23478  that the treasurer of wilkes county be and he ...         1  \n",
       "\n",
       "[23479 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert column 'sentence' to lowercase use map()\n",
    "combined_df['sentence'] = combined_df['sentence'].map(str.lower)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>sentence</th>\n",
       "      <th>jim_crow</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NORTH CAROLINA</th>\n",
       "      <td>14913</td>\n",
       "      <td>14913</td>\n",
       "      <td>14913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOUTH CAROLINA</th>\n",
       "      <td>8566</td>\n",
       "      <td>8566</td>\n",
       "      <td>8566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 year  sentence  jim_crow\n",
       "state                                    \n",
       "NORTH CAROLINA  14913     14913     14913\n",
       "SOUTH CAROLINA   8566      8566      8566"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of North Carolina and SOuth Carolina sentences\n",
    "count_df = combined_df.groupby('state').count()\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>sentence</th>\n",
       "      <th>jim_crow</th>\n",
       "      <th>sent_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1896</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>it shall be the duty of each county treasurer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1896</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>all moneys disbursed by any county treasurer o...</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1896</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>each county treasurer shall make out and forwa...</td>\n",
       "      <td>0</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1896</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>the county treasurer shall carry forward all s...</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1896</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>it shall be unlawful for any county treasurer,...</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23474</th>\n",
       "      <td>1909</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>on behalf of the general welfare of the city o...</td>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23475</th>\n",
       "      <td>1895</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>the clerk of the commissioners, on or before t...</td>\n",
       "      <td>1</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23476</th>\n",
       "      <td>1899</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>the township school trustees shall divide thei...</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23477</th>\n",
       "      <td>1899</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>they shall consult the convenience and necessi...</td>\n",
       "      <td>1</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23478</th>\n",
       "      <td>1901</td>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>that the treasurer of wilkes county be and he ...</td>\n",
       "      <td>1</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23479 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year           state  \\\n",
       "0      1896  SOUTH CAROLINA   \n",
       "1      1896  SOUTH CAROLINA   \n",
       "2      1896  SOUTH CAROLINA   \n",
       "3      1896  SOUTH CAROLINA   \n",
       "4      1896  SOUTH CAROLINA   \n",
       "...     ...             ...   \n",
       "23474  1909  NORTH CAROLINA   \n",
       "23475  1895  NORTH CAROLINA   \n",
       "23476  1899  NORTH CAROLINA   \n",
       "23477  1899  NORTH CAROLINA   \n",
       "23478  1901  NORTH CAROLINA   \n",
       "\n",
       "                                                sentence  jim_crow  \\\n",
       "0      it shall be the duty of each county treasurer ...         0   \n",
       "1      all moneys disbursed by any county treasurer o...         0   \n",
       "2      each county treasurer shall make out and forwa...         0   \n",
       "3      the county treasurer shall carry forward all s...         0   \n",
       "4      it shall be unlawful for any county treasurer,...         0   \n",
       "...                                                  ...       ...   \n",
       "23474  on behalf of the general welfare of the city o...         0   \n",
       "23475  the clerk of the commissioners, on or before t...         1   \n",
       "23476  the township school trustees shall divide thei...         0   \n",
       "23477  they shall consult the convenience and necessi...         1   \n",
       "23478  that the treasurer of wilkes county be and he ...         1   \n",
       "\n",
       "       sent_length  \n",
       "0              533  \n",
       "1              249  \n",
       "2              808  \n",
       "3              320  \n",
       "4              318  \n",
       "...            ...  \n",
       "23474          365  \n",
       "23475          477  \n",
       "23476          136  \n",
       "23477          282  \n",
       "23478          336  \n",
       "\n",
       "[23479 rows x 5 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find length of each sentence\n",
    "combined_df['sent_length'] = combined_df['sentence'].str.len()\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The longest sentence is of length: 8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Int64Index([5493, 15570], dtype='int64')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the max and min length of the sentence\n",
    "print(\" The longest sentence is of length:\", combined_df['sent_length'].max())\n",
    "\n",
    "# find the index of the row with longest sentence\n",
    "combined_df.index[combined_df['sent_length'] == 8889]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                                                        1901\n",
       "state                                             NORTH CAROLINA\n",
       "sentence       that j. n. price, h. l. price, e. m. moore, l....\n",
       "jim_crow                                                       0\n",
       "sent_length                                                 1115\n",
       "Name: 5298, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.iloc[5298,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2aab4248ffd0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "# Histogram for the sentence length\n",
    "sns.histplot(data=df, x=combined_df['sent_length'], bins = 100, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year           state                    sentence  jim_crow  sent_length\n",
      "58     1907  SOUTH CAROLINA    provided, further, that.         0           24\n",
      "73     1886  SOUTH CAROLINA      officers of the board.         0           22\n",
      "74     1886  SOUTH CAROLINA                   meetings.         0            9\n",
      "76     1886  SOUTH CAROLINA           local school tax.         0           17\n",
      "79     1886  SOUTH CAROLINA  and protected by his bond.         0           26\n",
      "...     ...             ...                         ...       ...          ...\n",
      "18113  1939  NORTH CAROLINA         purpose of the act.         0           20\n",
      "18115  1939  NORTH CAROLINA              appropriation.         0           14\n",
      "18154  1899  NORTH CAROLINA                           :         0            1\n",
      "18215  1907  NORTH CAROLINA                           q         0            1\n",
      "18219  1905  NORTH CAROLINA       manner of assessment.         0           21\n",
      "\n",
      "[681 rows x 5 columns]\n",
      "       year           state                sentence  jim_crow  sent_length\n",
      "11138  1952  SOUTH CAROLINA  negro county agent 72.         1           22\n",
      "      year           state                    sentence  jim_crow  sent_length\n",
      "69    1886  SOUTH CAROLINA              area and name.         2           14\n",
      "3665  1896  SOUTH CAROLINA  county board of education.         2           26\n"
     ]
    }
   ],
   "source": [
    "# find the rows whose sentence length is less than 27 words\n",
    "combined_df_27char = combined_df[combined_df['sent_length'] < 27]\n",
    "combined_df_27char.to_csv(\"combined_df_27char.csv\")\n",
    "\n",
    "# Find the number of sentences with labels \"0\", \"1\", and \"2\" in the dataframe with less than 27 charcters\n",
    "df0 = combined_df_27char[combined_df_27char['jim_crow'] == 0]\n",
    "df1 = combined_df_27char[combined_df_27char['jim_crow'] == 1]\n",
    "df2 = combined_df_27char[combined_df_27char['jim_crow'] == 2]\n",
    "print(df0)\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The number of sentences less than 25 characters are 463 and they are all labeled as 0 except one (labeled 2). So, we can delete all senetences whose length are less than 25.\n",
    "- The number of sentences less than 27 characters are 684 and they are all labeled as 0 except three (one labeled 1, two lableled 2). Since we do not want to delete any sentence coded as 1, we will delete all sentences less than 22 characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove all the sentences with < 22 characters. Create dataset with >= 22 characaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of rows in the reduced dataset: 23041\n"
     ]
    }
   ],
   "source": [
    "# Remove all the sentences whose length is <= characters\n",
    "df_updated = combined_df[combined_df['sent_length'] >= 22]\n",
    "print(\" Number of rows in the reduced dataset:\", len(df_updated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year            int64\n",
       "state          object\n",
       "sentence       object\n",
       "jim_crow        int64\n",
       "sent_length     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the data type of reduced dataframe columns\n",
    "df_updated.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences that are NOT jim crow = 18056\n",
      "Number of jim crow sentences = 4318\n",
      "Number of undecided sentences = 667\n"
     ]
    }
   ],
   "source": [
    "# Find the number of sentences with labels \"0\", \"1\", and \"2\"\n",
    "df_0 = df_updated[df_updated['jim_crow'] == 0]\n",
    "df_1 = df_updated[df_updated['jim_crow'] == 1]\n",
    "df_2 = df_updated[df_updated['jim_crow'] == 2]\n",
    "\n",
    "print(\"Number of sentences that are NOT jim crow =\", len(df_0))\n",
    "print(\"Number of jim crow sentences =\", len(df_1))\n",
    "print(\"Number of undecided sentences =\", len(df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year            int64\n",
       "state          object\n",
       "sentence       object\n",
       "jim_crow        int64\n",
       "sent_length     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_updated.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2aaaef1ea450>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from seaborn import countplot\n",
    "\n",
    "# Plot the distribution of the target (=1 that is jim_crow)\n",
    "countplot(x=df_updated['jim_crow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df_updated.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>sentence</th>\n",
       "      <th>jim_crow</th>\n",
       "      <th>sent_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [year, state, sentence, jim_crow, sent_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = df_updated[df_updated['jim_crow'] == 9]\n",
    "df_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stopwords from the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = stopwords.words(\"english\")\n",
    "\n",
    "# Define a function to remove stop words from a sentence \n",
    "def remove_stop_words(sentence): \n",
    "  # Split the sentence into individual words \n",
    "    words = sentence.split() \n",
    "  \n",
    "  # Use a list comprehension to remove stop words \n",
    "    filtered_words = [word for word in words if word not in stopWords] \n",
    "  \n",
    "  # Join the filtered words back into a sentence \n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        shall duty county treasurer report monthly, fi...\n",
       "1        moneys disbursed county treasurer account scho...\n",
       "2        county treasurer shall make forward state supe...\n",
       "3        county treasurer shall carry forward sums hand...\n",
       "4        shall unlawful county treasurer, county audito...\n",
       "                               ...                        \n",
       "23474    behalf general welfare city winston, good orde...\n",
       "23475    clerk commissioners, first monday november lis...\n",
       "23476    township school trustees shall divide respecti...\n",
       "23477    shall consult convenience necessities race set...\n",
       "23478    treasurer wilkes county hereby authorized pay ...\n",
       "Name: sentence, Length: 23041, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords from the 'sentence' column of the dataframe\n",
    "p=[]\n",
    "for i in df_updated['sentence']:\n",
    "    p.append(remove_stop_words(i))\n",
    "df_updated['sentence']=p\n",
    "df_updated['sentence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into 'features' and 'target' for machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "features = df_updated[['year', 'sentence']]\n",
    "target = df_updated['jim_crow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23041, 2) (23041,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1896</td>\n",
       "      <td>shall duty county treasurer report monthly, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1896</td>\n",
       "      <td>moneys disbursed county treasurer account scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1896</td>\n",
       "      <td>county treasurer shall make forward state supe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1896</td>\n",
       "      <td>county treasurer shall carry forward sums hand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1896</td>\n",
       "      <td>shall unlawful county treasurer, county audito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23474</th>\n",
       "      <td>1909</td>\n",
       "      <td>behalf general welfare city winston, good orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23475</th>\n",
       "      <td>1895</td>\n",
       "      <td>clerk commissioners, first monday november lis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23476</th>\n",
       "      <td>1899</td>\n",
       "      <td>township school trustees shall divide respecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23477</th>\n",
       "      <td>1899</td>\n",
       "      <td>shall consult convenience necessities race set...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23478</th>\n",
       "      <td>1901</td>\n",
       "      <td>treasurer wilkes county hereby authorized pay ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23041 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year                                           sentence\n",
       "0      1896  shall duty county treasurer report monthly, fi...\n",
       "1      1896  moneys disbursed county treasurer account scho...\n",
       "2      1896  county treasurer shall make forward state supe...\n",
       "3      1896  county treasurer shall carry forward sums hand...\n",
       "4      1896  shall unlawful county treasurer, county audito...\n",
       "...     ...                                                ...\n",
       "23474  1909  behalf general welfare city winston, good orde...\n",
       "23475  1895  clerk commissioners, first monday november lis...\n",
       "23476  1899  township school trustees shall divide respecti...\n",
       "23477  1899  shall consult convenience necessities race set...\n",
       "23478  1901  treasurer wilkes county hereby authorized pay ...\n",
       "\n",
       "[23041 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning: XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting test and training set in 20|80 ratio\n",
    "- Using default values of the parameter\n",
    "- Training and test set contains mixed of NC and SC sentences\n",
    "- Resample training data using imblearn SMOTEN as the dataset is very imbalanced - using SMOTEN because our dataset is purely categorical (https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTEN.html#imblearn.over_sampling.SMOTEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Randomly split X and y into training (80%) and test(20%) sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......TRAINING SET....\n",
      " Size of X_train is:  (18432, 2)\n",
      " Size of y_train is:  (18432,)\n",
      "......TEST SET....\n",
      " Size of X_test is:  (4609, 2)\n",
      " Size of y_test is:  (4609,)\n"
     ]
    }
   ],
   "source": [
    "print(\"......TRAINING SET....\")\n",
    "print(\" Size of X_train is: \", X_train.shape)\n",
    "print(\" Size of y_train is: \", y_train.shape)\n",
    "print(\"......TEST SET....\")\n",
    "print(\" Size of X_test is: \", X_test.shape)\n",
    "print(\" Size of y_test is: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count of 0,1,2 in training set BEFORE resampling using SMOTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 14505],\n",
       "       [    1,  3383],\n",
       "       [    2,   544]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting 0,1,2 in y_train \n",
    "np.array(np.unique(y_train, return_counts=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year         int64\n",
       "sentence    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample the data using SMOTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43515"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTEN(random_state=13)\n",
    "X_train, y_train = sm.fit_resample(X_train, np.array(y_train))\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count of 0,1,2 in training set AFTER resampling using SMOTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 14505],\n",
       "       [    1, 14505],\n",
       "       [    2, 14505]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of 0,1,2 after using SMOTEN\n",
    "np.array(np.unique(y_train, return_counts=True)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipeline for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectColumnsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "    def transform(self, X, **transform_params):\n",
    "        out = X[self.columns].copy()\n",
    "        return out\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Bayesian Hyperparameter search with HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            # Extract features\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('get_text', SelectColumnsTransformer(\"sentence\")),\n",
    "                ('vect', CountVectorizer(decode_error = \"ignore\",\n",
    "                      min_df = 2, max_df = 0.8)),\n",
    "                ('tfidf', 'passthrough'),\n",
    "            ])),\n",
    "#             ('text_len', Pipeline([\n",
    "#                 ('get_text', SelectColumnsTransformer(\"sentence\")),\n",
    "#                 ('length', LengthExtractor())\n",
    "#             ])),\n",
    "            ('metadata', SelectColumnsTransformer(['year']))\n",
    "        ])),\n",
    "        ('dlf',XGBClassifier(tree_method=\"hist\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|█         | 52/500 [08:40<2:30:43, 20.19s/trial, best loss: 0.03029879936567481] "
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    params['features__text_pipeline__vect__min_df'] = int(params['features__text_pipeline__vect__min_df'])\n",
    "    params['dlf__max_depth'] = int(params['dlf__max_depth'])\n",
    "    params['dlf__min_child_weight'] = int(params['dlf__min_child_weight'])\n",
    "    params['dlf__scale_pos_weight'] = int(params['dlf__scale_pos_weight'])\n",
    "    pipeline.set_params(**params)\n",
    "    \n",
    "    score = 1-cross_val_score(pipeline, X_train, y_train, scoring=make_scorer(f1_score, average=\"weighted\"),\n",
    "                              n_jobs=-1).mean()\n",
    "    #print(\"F1 {:.4f} params {}\".format((1-score), params))\n",
    "    return score\n",
    "\n",
    "space = {\n",
    "    'features__text_pipeline__vect__min_df': hp.quniform ('features__text_pipeline__vect__min_df',2,20,1),\n",
    "    'features__text_pipeline__vect__lowercase': hp.choice('features__text_pipeline__vect__lowercase',[True,False]),\n",
    "    'features__text_pipeline__vect__ngram_range': hp.choice('features__text_pipeline__vect__ngram_range',[(1,1),(1,2),(1,3),(1,4)]),\n",
    "    'features__text_pipeline__vect__max_df': hp.uniform('features__text_pipeline__vect__max_df',0.6,0.8),\n",
    "#     'features__text_len':hp.choice('features__text_len',[Pipeline([\n",
    "#             ('get_text', SelectColumnsTransformer(\"sentence\")),\n",
    "#             ('length', LengthExtractor())\n",
    "#         ])]),\n",
    "    'dlf__max_depth': hp.quniform('dlf__max_depth', 2, 10, 1),\n",
    "    'dlf__min_child_weight': hp.quniform('dlf__min_child_weight', 1, 5, 1),\n",
    "    'dlf__colsample_bytree': hp.uniform('dlf__colsample_bytree', 0.3, 1.0),\n",
    "    'dlf__learning_rate': hp.uniform('dlf__learning_rate', 0.05, 1),\n",
    "    'dlf__scale_pos_weight': hp.quniform('dlf__scale_pos_weight',1,8,1),\n",
    "    'dlf__gamma': hp.uniform('dlf__gamma',0,2)\n",
    "    \n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100, #actual fit was run with 1000 evals\n",
    "           trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_params = space_eval(space, best)\n",
    "model_params['features__text_pipeline__vect__min_df'] = int(model_params['features__text_pipeline__vect__min_df'])\n",
    "model_params['dlf__max_depth'] = int(model_params['dlf__max_depth'])\n",
    "model_params['dlf__min_child_weight'] = int(model_params['dlf__min_child_weight'])\n",
    "# model_params['dlf__scale_pos_weight'] = int(model_params['dlf__scale_pos_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle the model so that we don't have to run the whole file whenever we want to predict new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = pipeline\n",
    "best_model.set_params(**model_params)\n",
    "best_model.fit(X_train,y_train)\n",
    "\n",
    "# #pickle the best model\n",
    "# pickle.dump(best_model, open('best_model.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the model from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SelectColumnTransformer\n",
    "\n",
    "\n",
    "# if __name__=='__main__':\n",
    "#     best_model = pickle.load(open('best_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the labels of test data \n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# count the number of labels\n",
    "labels = np.unique(y_pred)\n",
    "\n",
    "data = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "\n",
    "# use sns.heatmap on top of confusion_matrix to show the confusion matrix\n",
    "sns.set(font_scale=1.4)\n",
    "ax = sns.heatmap(df_cm,xticklabels=True, annot=True, fmt='.0f', center=0.8, cmap='crest', linewidth=.5)\n",
    "ax.set(title=\"Overall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict \"label\" for the whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('../Split_Cleanup_Updated/updated_results/final_splits_Nov3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the column 'id' at '_'\n",
    "corpus['year']=corpus['id'].str.split('_')\n",
    "corpus.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = []\n",
    "for i in corpus['year']:\n",
    "        id.append(i[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(id))\n",
    "print(type(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(set(id))))\n",
    "list(set(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_new=[]\n",
    "for i in id:\n",
    "    if i.find('-') != -1:\n",
    "        year = i.split('-')[0]\n",
    "        id_new.append(year)\n",
    "    else:\n",
    "        id_new.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(id_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace the 2-year pairs with single years:\n",
    "- '1868-69' --> 1868\n",
    "- '1869-1870' --> 1869\n",
    "- '1870-1871' --> 1870\n",
    "- '1871-1872' --> 1871\n",
    "- '1872-1873' --> 1872\n",
    "- '1873-1874' --> 1873\n",
    "- '1875-76'   --> 1875\n",
    "- '1877-78'   --> 1877\n",
    "- '1881-82'   --> 1881\n",
    "- '1886-1887' --> 1886\n",
    "- '1958b'     --> 1958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_df['year'] = id_new\n",
    "# ct_year = corpus_df['year'].unique()\n",
    "# print(ct_year)\n",
    "# print(len(ct_year))\n",
    "\n",
    "corpus['year'] = id_new\n",
    "ct_year = corpus['year'].unique()\n",
    "print(ct_year)\n",
    "print(len(ct_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'year' 1958b to 1958\n",
    "# corpus_df.replace('1958b', '1958', inplace=True)\n",
    "corpus.replace('1958b', '1958', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(corpus_df['year'].unique())\n",
    "# print(len(corpus_df['year'].unique()))\n",
    "\n",
    "print(corpus['year'].unique())\n",
    "print(len(corpus['year'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_ml = corpus_df[['year', 'sentence']]\n",
    "# X_test_corpus.head()\n",
    "\n",
    "X_test_corpus = corpus[['year', 'sentence']]\n",
    "X_test_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_corpus.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the datatype of \"year\" and \"jim_crow\" to string in new_df1 \n",
    "X_test_corpus[['sentence']] = X_test_corpus[['sentence']].astype(str)\n",
    "X_test_corpus[['year']] = X_test_corpus[['year']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column 'sentence' to lowercase use map()\n",
    "X_test_corpus['sentence'] = X_test_corpus['sentence'].map(str.lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_ml = X_test_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_corpus=[]\n",
    "\n",
    "# Remove stopwords from the 'sentence' column of the dataframe\n",
    "new_sentences=[]\n",
    "for i in X_test_corpus['sentence']:\n",
    "    p_corpus.append(remove_stop_words(i))\n",
    "X_test_corpus['sentence'] = p_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #predict the labels of test data \n",
    "# y_pred_corpus = best_model.predict(X_test_ml)\n",
    "\n",
    "# # count the number of labels\n",
    "# corpus_df['predicted_label'] = y_pred_corpus\n",
    "\n",
    "#predict the labels of test data \n",
    "y_pred_corpus = best_model.predict(X_test_corpus)\n",
    "\n",
    "# # count the number of labels\n",
    "# corpus_df['predicted_label'] = y_pred_corpus\n",
    "\n",
    "# count the number of labels\n",
    "corpus['predicted_label'] = y_pred_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the corpus with predicted data in a csv file\n",
    "corpus.to_csv(\"Predicted_Data_Labels/PredLabels_corpus.csv\")\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, g in corpus.groupby('year'):\n",
    "    print('i is', i)\n",
    "    print(\"g is\", g)\n",
    "    df=g\n",
    "    df.to_csv(f'Predicted_Data_Labels/{year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_by_year = corpus.groupby('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = dict(list(corpus_by_year))\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in groups.items():\n",
    "    val.to_csv(f'Predicted_Data_Labels/predicted_{key}.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
