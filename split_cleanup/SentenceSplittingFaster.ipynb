{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2409e4ce-2e4f-4029-ae7c-842dfa3294a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Faster Sentence Splitting\n",
    "This notebook uses OCRed text for a volume year and splits it into sentences using regular expression pattern matching.<br>\n",
    "For this notebook to run, there should be an OCRed folder that should contain a .txt file, a .tsv file, and an images sub-folder (more details in the notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d00b4a-49ba-48b4-a21c-a08644a3c74a",
   "metadata": {},
   "source": [
    "This notebook trades some of the visual outputs that were used in `SentenceSplitting.ipynb` (that might have been helpful to the reader) in exchange for faster, less descriptive, code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6261971e-eaad-4191-a8f9-279c31471815",
   "metadata": {},
   "source": [
    "<b>Note:</b>\n",
    "- If the Acts and Joints were mixed for the chosen year, the OCRed output will contain `{year}_Both.txt` and `{year}_Both_data.tsv`\n",
    "- If the Acts and Joints were seperate for the chosen year, the OCRed output will contain `{year}_Acts.txt` and `{year}_Acts_data.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ce678b-a95e-48af-b86f-f96be48a238c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T21:10:35.381355Z",
     "start_time": "2023-07-12T21:10:35.372055Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d66ec11-f426-4dae-94d3-a834d27f8dfa",
   "metadata": {},
   "source": [
    "<br>\n",
    "Either get the year variable from elsewhere (such as when this notebook is accessed from another file) or specify the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c488195-d210-4c2e-854f-5936a66dc194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the year variable from somewhere else\n",
    "%store -r year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6b101c-1fbb-4a41-a3b7-5ce88b10bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If running this notebook independently,\n",
    "# # Uncoment the following line of code\n",
    "# year = 1893"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4feccc3-04a2-4689-9b18-6052d27df568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 1901 under /Users/nitingupta/Desktop/OTB/OCRed/1901\n"
     ]
    }
   ],
   "source": [
    "# This is the directory that will contain the OCRed output:\n",
    "dir_OCR = \"/Users/nitingupta/Desktop/OTB/OCRed/\" + str(year)\n",
    "\n",
    "print(f\"Working on {year} under {dir_OCR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55b1c4b-ad16-4478-90ac-7be1b3b8aa99",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Try reading in \"{year}_text.txt\" if the Acts and Joints were seperate for the year\n",
    "try:\n",
    "    acts_path = dir_OCR + \"/\" + str(year) + \"_Acts.txt\"\n",
    "    with open(acts_path, 'r') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    # If the read is successful, set a flag that identifies that the Acts and Joints are seperate\n",
    "    actsSep = True\n",
    "\n",
    "# However, if the directory contains {year}_Both.txt instead, a FileNotFoundError will be returned for the above code.\n",
    "# So, catch that error and read in \"{year}_Both.txt\"\n",
    "except FileNotFoundError:\n",
    "    acts_path = dir_OCR + \"/\" + str(year) + \"_Both.txt\"\n",
    "    with open(acts_path, 'r') as f:\n",
    "        data = f.read()\n",
    "    \n",
    "    actsSep = False  # The flag being False means that the Acts and Joints are not seperate\n",
    "\n",
    "# This variable holds all the OCRed text as a String\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9839aca-b497-4efe-9d19-855a2df045d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of pages OCRed for 1901 is: 258\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of pages OCRed for {year} is: {count}\".format(year = year, count = (data.count(\"\\n\\n\")+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe794dde-3fe2-4f02-93f8-3d6098e0866b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba46f133-3523-4079-9bbf-b19400f1c3cf",
   "metadata": {},
   "source": [
    "## A. Training the tokenizer\n",
    "Based on this [article](https://subscription.packtpub.com/book/application-development/9781782167853/1/ch01lvl1sec12/training-a-sentence-tokenizer),\n",
    "- NLTK's default sentence tokenizer is general purpose and usually works quite well. But sometimes it might not be the best choice for our text if it uses nonstandard punctuation or is formatted in a unique way. In such cases, training your own sentence tokenizer can result in much more accurate sentence tokenization.\n",
    "- The `PunktSentenceTokenizer` class uses an unsupervised learning algorithm to learn what constitutes a sentence break.\n",
    "    - The specific technique used in this case is called sentence boundary detection. It works by counting punctuation and tokens that commonly end a sentence, such as a period or a newline, then using the resulting frequencies to decide the sentence boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "084e787f-ba8d-4f47-a8e0-5b2d3b7cc708",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sent_tokenizer = PunktSentenceTokenizer(data)\n",
    "sentences = sent_tokenizer.tokenize(data)\n",
    "\n",
    "# A List of tokens/sentences as seperated by nltk's PunktSentenceTokenizer\n",
    "# sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5697fa-8a7b-4575-9a70-e334f4e4f175",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a408d-8d8e-4dd9-8d3d-1ad62e1dead1",
   "metadata": {},
   "source": [
    "## B. Creating the dataframe\n",
    "Make a new dataframe with the sentences and lengths as a features.\n",
    "<br>Other features will be added later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "991c17c5-5ad3-4371-8380-6728bee2863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to a new DataFrame\n",
    "df = pd.DataFrame()\n",
    "df[\"sentence\"] = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d343cde9-c499-4e1c-8cd5-1c183c267033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Strip sentences of trailing and leading whitespaces\n",
    "df['sentence'] = df['sentence'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d5e4176-aa1b-42b2-af4b-2bc2167be841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the initial dataframe: 1864 \n",
      "This is the number of tokenized sentences.\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the initial dataframe:\", df.shape[0], \"\\nThis is the number of tokenized sentences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1c4b9c-b677-46c0-aa2c-4edb32488386",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb28216-d4fb-4409-bfbf-403d1c3e2727",
   "metadata": {
    "tags": []
   },
   "source": [
    "## C. Adding page file names\n",
    "- Add an feature that specifies which page number that sentence starts and ends on.\n",
    "- Reading only Acts. <b> Not reading Joints </b>\n",
    "- The reason to read the files from the directory is to ensure that missing file pages are not missed in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a008ea8-445d-48f7-9de4-e3302b38db5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images directory is /Users/nitingupta/Desktop/OTB/OCRed/1901/images\n"
     ]
    }
   ],
   "source": [
    "# This is the path to the directory that contains the images.\n",
    "# NOTE: This directory is inside the OCRed output for the chosen year\n",
    "dir_imgs = dir_OCR + \"/images\"\n",
    "print(f\"The images directory is {dir_imgs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8716cafc-aefb-4920-ac01-e5cc88c4250c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of image files for this year is: 270\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    imgs = listdir(dir_imgs)\n",
    "except:\n",
    "    imgs = listdir(dir_imgs+'.zip')\n",
    "imgs = [img for img in imgs if \"jpg\" in img or \"tiff\" in img or \"JPG\" in img or \"TIFF\" in img]\n",
    "imgs.sort()\n",
    "print(\"The number of image files for this year is:\", len(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f3f7dc7-9d14-43db-af56-c1c644b1b882",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files are of type: jpg\n"
     ]
    }
   ],
   "source": [
    "fileType = imgs[0].split(\".\")[1]\n",
    "print(f\"The files are of type: {fileType}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca102b90-a98d-4407-9e9a-85d234537da5",
   "metadata": {},
   "source": [
    "<b>Note:</b>\n",
    "- The OCR attempts to seperates new pages by adding \"\\n\\n\". However, the total number of pages does not equal the total count of \"\\n\\n\" in the text as the OCR does not add \"\\n\\n\" after every page.\n",
    "- One way to eliminate this issue is by utilizing the `{year}_Both_data.tsv` (if acts and joints mixed) or `{year}_Acts_data.tsv` (if acts and joints seperated) file from the OCR output.\n",
    "- This file contains each word (in the 2nd last column) and the filename for that word (last column).\n",
    "- Also, since we are only working with Acts, if the Acts and Joints are seperate, the last word in the df_word dataframe will not end on the actual last page in the images sub-folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb9b0292-77f3-40c7-9df5-fc5572944b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>top</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>conf</th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1592</td>\n",
       "      <td>2536</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00035.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>728</td>\n",
       "      <td>283</td>\n",
       "      <td>60</td>\n",
       "      <td>144</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00035.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>728</td>\n",
       "      <td>257</td>\n",
       "      <td>180</td>\n",
       "      <td>170</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00035.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>728</td>\n",
       "      <td>283</td>\n",
       "      <td>60</td>\n",
       "      <td>144</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00035.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>283</td>\n",
       "      <td>60</td>\n",
       "      <td>144</td>\n",
       "      <td>34.161140</td>\n",
       "      <td>IK</td>\n",
       "      <td>00035.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127981</th>\n",
       "      <td>682</td>\n",
       "      <td>1851</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>95.772659</td>\n",
       "      <td>of</td>\n",
       "      <td>00292.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127982</th>\n",
       "      <td>735</td>\n",
       "      <td>1851</td>\n",
       "      <td>174</td>\n",
       "      <td>39</td>\n",
       "      <td>96.576187</td>\n",
       "      <td>February,</td>\n",
       "      <td>00292.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127983</th>\n",
       "      <td>926</td>\n",
       "      <td>1851</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>92.059761</td>\n",
       "      <td>A.</td>\n",
       "      <td>00292.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127984</th>\n",
       "      <td>984</td>\n",
       "      <td>1851</td>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>92.059761</td>\n",
       "      <td>D.</td>\n",
       "      <td>00292.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127985</th>\n",
       "      <td>1043</td>\n",
       "      <td>1859</td>\n",
       "      <td>87</td>\n",
       "      <td>31</td>\n",
       "      <td>6.582840</td>\n",
       "      <td>1goI.</td>\n",
       "      <td>00292.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127986 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        left   top  width  height       conf       text       name\n",
       "0          0     0   1592    2536  -1.000000        NaN  00035.jpg\n",
       "1        728   283     60     144  -1.000000        NaN  00035.jpg\n",
       "2        728   257    180     170  -1.000000        NaN  00035.jpg\n",
       "3        728   283     60     144  -1.000000        NaN  00035.jpg\n",
       "4        728   283     60     144  34.161140         IK  00035.jpg\n",
       "...      ...   ...    ...     ...        ...        ...        ...\n",
       "127981   682  1851     38      31  95.772659         of  00292.jpg\n",
       "127982   735  1851    174      39  96.576187  February,  00292.jpg\n",
       "127983   926  1851     40      31  92.059761         A.  00292.jpg\n",
       "127984   984  1851     39      31  92.059761         D.  00292.jpg\n",
       "127985  1043  1859     87      31   6.582840      1goI.  00292.jpg\n",
       "\n",
       "[127986 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Based on whether the Acts and Joints are mixed, read the appropriate tsv file\n",
    "if actsSep:\n",
    "    df_words = pd.read_table(f\"{dir_OCR}/{year}_Acts_data.tsv\")\n",
    "else:\n",
    "    df_words = pd.read_table(f\"{dir_OCR}/{year}_Both_data.tsv\")\n",
    "\n",
    "df_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deaebfe-30b8-4078-9543-cf10059129ac",
   "metadata": {},
   "source": [
    "So, to label the page numbers in the dataframe, we can go through the original dataframe and find the start and end words in each sentence.\n",
    "<br>We, can then find the page numbers for those words, from `df_words` and add them to the original dataframe, `df`.\n",
    "<br>To start, we need to clean the two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5474d57-cba4-4a4b-8f69-832dbcdeb840",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['page'] = pd.NA\n",
    "\n",
    "# Drop the columns which are unessecary for our analysis\n",
    "df_words.drop(columns=[\"left\", \"top\", \"width\", \"height\", \"conf\"], inplace=True)\n",
    "\n",
    "# Drop the rows which don't contain a word in the \"text\" column\n",
    "df_words.dropna(inplace=True)\n",
    "\n",
    "# Relabel the \"name\" column to \"page\" column\n",
    "df_words.rename(columns={\"name\": \"page\"}, inplace=True)\n",
    "\n",
    "# Reassign index after dropping nas\n",
    "df_words = df_words.assign(row_number=range(len(df_words)))\n",
    "df_words.set_index('row_number', inplace=True)\n",
    "\n",
    "# Drop the 'page' column from the org dataframe\n",
    "df.drop(columns=['page'], inplace=True)\n",
    "\n",
    "# Add an empty 'start_page' and 'end_page' column\n",
    "df['start_page'] = pd.NA\n",
    "df['end_page'] = pd.NA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fba37f-602b-4256-9d0e-e58ed172d65d",
   "metadata": {},
   "source": [
    "Since, a word can only exist on a single page, we have unique identifiers for the start and end page for each sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96e2eb75-7f5b-45ca-8cdd-6c8cbac0206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"\\n\\n\" from the original dataframe as they will interfere with the analysis\n",
    "df['sentence'] = df['sentence'].str.replace(\"\\n\\n\", \"\", regex = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c50f2d2a-938f-4e58-b055-a15eb8e65cef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tracker for df_words:\n",
    "words_trkr = 0\n",
    "\n",
    "# Loop over the original dataframe\n",
    "for i in range(0, df.shape[0]):\n",
    "\n",
    "    # For each sentence, extract the first and last word\n",
    "    tmp_sentence = df.iloc[i]['sentence'].split(\" \")\n",
    "    start, last = tmp_sentence[0], tmp_sentence[-1]\n",
    "\n",
    "    # Get the page number for the start and end word\n",
    "    start_page = df_words.iloc[words_trkr]['page']\n",
    "\n",
    "    try:\n",
    "        end_page = df_words.iloc[words_trkr + len(tmp_sentence)]['page']\n",
    "    except:\n",
    "        end_page = df_words.iloc[words_trkr]['page']\n",
    "        \n",
    "\n",
    "    # Remove the filename from the pages:\n",
    "    start_page = start_page.split(\".\")[0]\n",
    "    end_page = end_page.split(\".\")[0]\n",
    "\n",
    "    \n",
    "    # Assign the page number to their respective columns in the dataframe\n",
    "    df.at[i, 'start_page'] = start_page\n",
    "    df.at[i, 'end_page'] = end_page\n",
    "    \n",
    "    # Update tracker\n",
    "    words_trkr += len(tmp_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f7e208f-775a-4233-9c3f-a8bc376f96b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>SECTION 1. Be it enacted by the General Assembly of the State of South Carolina: That the County Board of Commis- sioners of Cherokee County be, and they are hereby, authorized, if in their discretion they deem that it is for the best interest of said County, to borrow a sum of money from the Sinking Fund of the State of South Carolina, not to exceed ten thousand dol- lars, at a rate of interest not to exceed five per centum per an- num, for the purpose of building a bridge across Broad River, in said County, at such point on said river as they may deem most practicable, and a special tax of one-half mill on the dollar may be levied on all taxable property in the County of Chero- kee, provided the Board of Commissioners so decide to build said bridge, for the said period of seven years, for the purpose of repaying said loan.</td>\n",
       "      <td>00292</td>\n",
       "      <td>00292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>That the proceeds of said levy of one- half mill shall be paid each year on said loan until the seventh year, in which year the balance remaining due on said loan shall be paid from said special levy, if any remain it shall-be turned into the County Treasury for ordinary County purposes, and if a’sufficient sum has not been realized by said special levy at the expiration of said seven years the deficiency shall be paid by the County Board of Commissioners out of the ordinary County funds.</td>\n",
       "      <td>00292</td>\n",
       "      <td>00292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>Sec. 2.</td>\n",
       "      <td>00292</td>\n",
       "      <td>00292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>That the Commissioners of the Sinking Fund of the State of South Carolina are hereby authorized to lend to the County Board of Commissioners of Cherokee County out of the funds in their hands, the sum of ten thousand dollars, to be used for building said bridge, said sum to be secured by the special levy as herein provided for in Section one.</td>\n",
       "      <td>00292</td>\n",
       "      <td>00292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>Approved the 2oth day of February, A. D. 1goI.</td>\n",
       "      <td>00292</td>\n",
       "      <td>00292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  sentence  \\\n",
       "1859  SECTION 1. Be it enacted by the General Assembly of the State of South Carolina: That the County Board of Commis- sioners of Cherokee County be, and they are hereby, authorized, if in their discretion they deem that it is for the best interest of said County, to borrow a sum of money from the Sinking Fund of the State of South Carolina, not to exceed ten thousand dol- lars, at a rate of interest not to exceed five per centum per an- num, for the purpose of building a bridge across Broad River, in said County, at such point on said river as they may deem most practicable, and a special tax of one-half mill on the dollar may be levied on all taxable property in the County of Chero- kee, provided the Board of Commissioners so decide to build said bridge, for the said period of seven years, for the purpose of repaying said loan.   \n",
       "1860                                                                                                                                                                                                                                                                                                                                                         That the proceeds of said levy of one- half mill shall be paid each year on said loan until the seventh year, in which year the balance remaining due on said loan shall be paid from said special levy, if any remain it shall-be turned into the County Treasury for ordinary County purposes, and if a’sufficient sum has not been realized by said special levy at the expiration of said seven years the deficiency shall be paid by the County Board of Commissioners out of the ordinary County funds.   \n",
       "1861                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Sec. 2.   \n",
       "1862                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              That the Commissioners of the Sinking Fund of the State of South Carolina are hereby authorized to lend to the County Board of Commissioners of Cherokee County out of the funds in their hands, the sum of ten thousand dollars, to be used for building said bridge, said sum to be secured by the special levy as herein provided for in Section one.   \n",
       "1863                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Approved the 2oth day of February, A. D. 1goI.   \n",
       "\n",
       "     start_page end_page  \n",
       "1859      00292    00292  \n",
       "1860      00292    00292  \n",
       "1861      00292    00292  \n",
       "1862      00292    00292  \n",
       "1863      00292    00292  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d3256-7f66-42ab-b5f9-263c1f40f6b3",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b639c194-db50-4444-ba6f-a9eb376ad89a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## D. Further Cleaning and Regex\n",
    "Remove unecessary words in the sentences which do not contribute to the overall meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0ae0635-75aa-44af-afa7-82872093d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataframe so that the results of the matching can be compared\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# A new dictionary to keep track of the number of errors\n",
    "errorsDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3490cba-5742-4004-8b1f-c211f59da561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IK OF THE | GENERAL ASSEMBLY.</td>\n",
       "      <td>00035</td>\n",
       "      <td>00035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OF THE STATE OF SOUTH CAROLINA Passed at the Regular Session which was begun and held at the City of Co- lumbia on the Eighth Day of January, A. D. 1961 and was adjourned without day on the Sicteenth day of February, A. D. 1901.</td>\n",
       "      <td>00035</td>\n",
       "      <td>00035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M. B. McSweeney, Governor.</td>\n",
       "      <td>00035</td>\n",
       "      <td>00035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jas. H. TittMan, Lieutenant- Governor and ex officio President of the Senate.</td>\n",
       "      <td>00035</td>\n",
       "      <td>00035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W. F STEVENSON, Speaker of the House of Representatives Rorert R. HEMPHILL, Clerk of the Senate.</td>\n",
       "      <td>00035</td>\n",
       "      <td>00035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                               sentence  \\\n",
       "0                                                                                                                                                                                                         IK OF THE | GENERAL ASSEMBLY.   \n",
       "1  OF THE STATE OF SOUTH CAROLINA Passed at the Regular Session which was begun and held at the City of Co- lumbia on the Eighth Day of January, A. D. 1961 and was adjourned without day on the Sicteenth day of February, A. D. 1901.   \n",
       "2                                                                                                                                                                                                            M. B. McSweeney, Governor.   \n",
       "3                                                                                                                                                         Jas. H. TittMan, Lieutenant- Governor and ex officio President of the Senate.   \n",
       "4                                                                                                                                      W. F STEVENSON, Speaker of the House of Representatives Rorert R. HEMPHILL, Clerk of the Senate.   \n",
       "\n",
       "  start_page end_page  \n",
       "0      00035    00035  \n",
       "1      00035    00035  \n",
       "2      00035    00035  \n",
       "3      00035    00035  \n",
       "4      00035    00035  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e332003-850b-427a-bb4a-d3e533374356",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7102c656-de20-4078-950c-eb0140134fe8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Removing section identifiers\n",
    "The following code implements regex patterns to identify sections, such as \"Section 1.\", \"Sec. 4.\", etc. \n",
    "<br>Since most sections, which need to be removed, appear either at the start or the start of the ORCed sentence, the pattern finds matches either at the start or the end of the sentence.\n",
    "<br>Do note that the same pattern is repeated for the start and end of the sentence, and is seperated by '|'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a72579-6be3-4aef-86ec-88e8d3bc2a4d",
   "metadata": {},
   "source": [
    "Some notes about the pattern:\n",
    "- `r'(S|s|E|e|C|c|T|t|I|i|O|o|N|n){2,}'` matches \"Section\"\n",
    "- `r'(\\.|,|:|;| )'{0,2}` matches mistaken delimiters or spaces following \"Section\"\n",
    "- `r'[0Oo1Iil!2Z5S6G\\d]{1,2}'` matches the section number. Letters are required in this pattern to account for OCR mistakes\n",
    "- `r'(. |.| |)'` matches the end of phrase spaces and periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc4db9c8-5ea5-436a-bdc3-4d80d94b9334",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "errorsDict['section identifiers'] = df_cleaned['sentence'].str.count(pat = r\"^(S|s|E|e|C|c|T|t|I|i|O|o|N|n){2,}(\\.|,|:|;| ){0,2}[0Oo1Iil!2Z5S6G\\d]{1,2}(. |.| |)|(S|s|E|e|C|c|T|t|I|i|O|o|N|n){2,}(\\.|,|:|;| ){0,2}[0Oo1Iil!2Z5S6G\\d]{1,2}(. |.| |)$\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c6f5ee0-c020-4610-abae-477f9ef82f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cleaned['sentence'] = df_cleaned['sentence'].str.replace(pat = r\"^(S|s|E|e|C|c|T|t|I|i|O|o|N|n){2,}(\\.|,|:|;| ){0,2}[0Oo1Iil!2Z5S6G\\d]{1,2}(. |.| |)|(S|s|E|e|C|c|T|t|I|i|O|o|N|n){2,}(\\.|,|:|;| ){0,2}[0Oo1Iil!2Z5S6G\\d]{1,2}(. |.| |)$\",\n",
    "                                                            repl = \"\",\n",
    "                                                            regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17567a4e-23d7-4c7f-9436-275ba5c01555",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da10614-bbb0-417d-b642-f82a0ff77b0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Removing end of line hyphenation\n",
    "Whenever a word in the sentence continues from the end of a line to the beginning of the next line and is joined by a hyphen, the OCRed sentence also contains that hyphen and a space.\n",
    "<br>For example, 'Commander-in-Chief' is OCRed as 'Com- mander-in-Chief'\n",
    "<br>The following code implements regex patterns to remove \"- \" in the text since each hyphenated word is split with \"- \"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2c3e1c3-53d7-46b0-abf8-1b7c04976c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "errorsDict['EOL hyphenation'] = df_cleaned['sentence'].str.count(pat = '[-][ ]').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3772a778-2bea-463c-8a3b-7b2663b11b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cleaned['sentence'] = df_cleaned['sentence'].str.replace(pat = '[-][ ]',\n",
    "                                                            repl = \"\",\n",
    "                                                            regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72d325d-db8c-489b-9581-8986a2da64b9",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da1064a-5502-4371-9f3d-82e1fca06965",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Relocating incorrect \"Approved ...\" phrases\n",
    "The “Approved…” phrases are incorrectly appended to the start of the next law. They should by appended to the end of the previous law.\n",
    "<br>Phrases might be of the format: \n",
    "- \"Approved the 2oth day of February, A. D. 1901\",\n",
    "- \"Approved December 15th, A. D. 1892.\",\n",
    "- \"Approved December O5th, A. D. 1892.\",\n",
    "- \"Approved December !2th, A. D. 1892.\",\n",
    "- \"Approved December 6Gth, A. D. 1892.\",\n",
    "- \"Approved December 05th, A. D. 1892.\","
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fc0ac7-7db3-41e4-a1dd-f900848bf1d1",
   "metadata": {},
   "source": [
    "Since phrases might either have the month or the date after the \"Approved\" sub-string, the code below utilized two patterns to account for either case, seperated by '|'.\n",
    "<br>\n",
    "Some notes about the pattern:\n",
    "- `r'[0Oo1Iil!2Z5S6G\\d]{1,2}'` matches the date. Letters are required in this pattern to account for OCR mistakes\n",
    "- `r'(?:th|st|nd|rd)'` matches the prefixes for the dates\n",
    "- `r'[A-Z][a-z]+'` matches the month\n",
    "- `r'.{4}'` matches years\n",
    "- `r'(. |.| |)'` matches the end of phrase spaces and periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e84e81d6-95e3-4602-aa69-cf4c23469fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A seperate and special method is needed for this match\n",
    "# because the match will be appended to the previous law\n",
    "def replaceInDF(rgx_match: re.Pattern, df: pd.DataFrame, retCount = False):\n",
    "    '''\n",
    "    Find the provided regex pattern in the provided dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rgx_match : re.Pattern\n",
    "        A regular expression pattern that will be search for and replaced in the df\n",
    "    df: pandas.Dataframe\n",
    "        A Pandas dataframe to search and replace for\n",
    "        Should contain a 'sentence' column, in which the matches which will be replaced\n",
    "    retCount: Boolean\n",
    "        A flag to identify whether the function should return the number of matches.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    if retCount == True:\n",
    "        A tuple consisting of:\n",
    "            df: pandas.Dataframe\n",
    "            The modified Dataframe with the matches performed\n",
    "            errorCount: int\n",
    "            A count of how many times this error was found.\n",
    "    else:\n",
    "        df: pandas.Dataframe\n",
    "        The modified Dataframe with the matches performed\n",
    "    '''\n",
    "    \n",
    "    if retCount:\n",
    "        errorCount = 0\n",
    "    \n",
    "    for i in range(0, df.shape[0]):\n",
    "        \n",
    "        # Look for matches\n",
    "        m = re.search(rgx_match, df.iloc[i]['sentence'])\n",
    "\n",
    "        # If matches found then add to the previous sentence\n",
    "        if m:\n",
    "            df.at[i-1, 'sentence'] = df.iloc[i-1]['sentence'] + \" \" + str(m.group())\n",
    "    \n",
    "    \n",
    "        if retCount:\n",
    "            # Remove the matched patterns from sentences\n",
    "            df.at[i, 'sentence'], numError = re.subn(rgx_match, '', df.iloc[i]['sentence'])\n",
    "            errorCount += numError\n",
    "        else:\n",
    "            df.at[i, 'sentence'] = re.sub(rgx_match, '', df.iloc[i]['sentence'])\n",
    "        \n",
    "    if retCount:\n",
    "        return df, errorCount\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcba4fd1-6857-4217-809f-8f277e077352",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgx_match = re.compile(\n",
    "    r'^Approved the [0Oo1Iil!2Z5S6G\\d]{1,2}(?:th|st|nd|rd) day of [A-Z][a-z]+, A\\. D\\. .{4}(. |.| |)\\b|Approved [A-Z][a-z]+ [0Oo1Iil!2Z5S6G\\d]{1,2}(?:th|st|nd|rd), A\\. D\\. .{4}(. |.| |)\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0cd90ce-a194-410e-9a71-6fc6b22980bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_cleaned = replaceInDF(rgx_match, df_cleaned, retCount=False)\n",
    "df_cleaned, errorsDict['Approved phrases'] = replaceInDF(rgx_match, df_cleaned, retCount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0df6c7-380a-497c-81a1-216a9bf2b824",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab2da0f-3d43-4b4e-b8f9-e64061ab9b32",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Removing Act seperators\n",
    "The horizontal lines differentiating one Act from another show up as U+2014 : EM DASH characters (one or multiple) in the OCR.\n",
    "<br>For example, '——- —— AN ACT...' or '—— AN ACT...'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b379ea0-57e1-4435-b26d-49b7eb7768f4",
   "metadata": {},
   "source": [
    "Some notes about the pattern:\n",
    "- `r'^—+'` matches one or more consecutive occurrences of the \"—\" character at the start of a line.\n",
    "- `r'(?=\\s*[A-Za-z])'` is a positive lookahead (this part isn't captured) that checks if there is zero or more whitespace characters (\\s*) followed by a letter ([A-Za-z]) after the \"—\" characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9de7baf7-38f4-4aca-a927-1f611fc8b4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "errorsDict['Act seperators'] = df_cleaned['sentence'].str.count(pat = r'^—+(?=\\s*[A-Za-z])').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17a8b3c9-36a8-4fae-9afb-0e9cf3a51cab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cleaned['sentence'] = df_cleaned['sentence'].str.replace(pat = r'^—+(?=\\s*[A-Za-z])',\n",
    "                                                            repl = \"\",\n",
    "                                                            regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b41cb49-38f2-4dbf-b32d-3fdb51824926",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d59afb-2023-4127-878d-5b03c9d5b1c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5. Removing incorrect numbers at the start\n",
    "Some numbers are incorrectly left at the start of the sentence from the OCR process. They are rather OCRed, for example, as 2, or 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb88befb-cf7f-48b4-ac02-4560ab50c499",
   "metadata": {},
   "source": [
    "Some notes about the pattern:\n",
    "- `r'^[0Oo1Iil!2Z5S6G\\d]{1,3}'` matches upto 3 numbers at the start of the string\n",
    "- `r'(. |.| |)'` matches the end of phrase spaces and periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b70a01e1-ca75-4cd2-afd9-fd7fbc9d2da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "errorsDict['Incorrect starting nums'] = df_cleaned['sentence'].str.count(pat = r'^[0Oo1Iil!2Z5S6G\\d]{1,3}(. |.| |)').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80a228f2-c5b6-4374-b8a1-5da43915a899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cleaned['sentence'] = df_cleaned['sentence'].str.replace(pat = r'^[0Oo1Iil!2Z5S6G\\d]{1,3}(. |.| |)',\n",
    "                                                            repl = \"\",\n",
    "                                                            regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3eac7a-ca83-4760-a97f-73daf4c2481b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59b661c-9e68-490b-bac8-db3b4bf0af87",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6. Removing session headers\n",
    "For some volumes, the OCRed text includes information about the session held (which is usually found on the first page).\n",
    "<br>The first valid sentence starts with \"An Acts ...\". So, to remove them, the code removes all sentences until the first valid sentence appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40902635-ed6c-408d-b528-1053f48b9e12",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "disregarded = 0  # Count for the number removed\n",
    "\n",
    "for i, sent in enumerate(df_cleaned['sentence']):\n",
    "\n",
    "    # If the sentence with \"an\" is found, exit the loop\n",
    "    if sent.lower().strip().startswith(\"an\"):\n",
    "           break\n",
    "    \n",
    "    # Disregard the sentence since it does not start with \"an\"\n",
    "    df_cleaned.drop(index=i, inplace=True)\n",
    "    disregarded += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6025ad13-cc49-493b-b65a-0d9d26d0f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "df_cleaned.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5cebf22-a33e-4f99-a79d-84ffbec33f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences disregarded: 7.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of sentences disregarded: {disregarded}.\")\n",
    "errorsDict['Session headers'] = disregarded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76117e8f-1d68-4b42-8982-c700766d08e1",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15dd4ac-0ec0-401f-a107-954c449e03e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 7. Converting to uppercase\n",
    "For some sentence, the OCR process outputs few words as a mix of upper and lower case letters. To help in producing human readable digitized text, the following piece of code detects and changes words to all uppercase.\n",
    "<br>While this step might not be a priority for computational analysis, it is an important step to help improve the readability of the sentences\n",
    "<br>An example, \"AN ACT FoR THE PROTECTION OF THE AIDS TO NAVIGATION EsTABLISHED BY THE AUTHORITY OF THE UNITED STATES LicgHt Hovust BoarD WITHIN THE STATE OF SOUTH CAROLINA.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b31267e1-c397-4fac-8a16-7c2c3bae3e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upperIfNeeded(sentence, ratio = 0.50):\n",
    "    '''\n",
    "    Convert the given sentence list into an uppercase sentence list\n",
    "    if the ratio of uppercase words (not including the ones with a mix of digits \n",
    "    or words like \"SECTION\") to the total words is greater than a fixed value.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence: str\n",
    "         A str of sentence to check and convert to uppercase\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    sentence: str\n",
    "        If check is approved the return an uppercase version of str.\n",
    "        Else return the sentence.\n",
    "    '''\n",
    "    \n",
    "    count = 0  # A count of the number of already uppercased words\n",
    "    \n",
    "    for word in sentence.split(\" \"):\n",
    "        # Check whether the word consists of only letters,\n",
    "        # has a length greater than 1, is uppercase, and \n",
    "        # isn't \"SECTION\"\n",
    "        if word.isalpha() and len(word) > 1 and word.isupper() and word != \"SECTION\":\n",
    "            count += 1\n",
    "\n",
    "    # If the count to words ratio is greater\n",
    "    if (count/len(sentence.split(\" \")) > ratio):\n",
    "        # Return all uppercase words\n",
    "        return sentence.upper()        \n",
    "    \n",
    "    # Else, return the original sentence list\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b8e20a6-b594-4756-84f0-cafefd555508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the above function to each sentence in 'org_sent'\n",
    "# And store the output a new column named 'modified'\n",
    "df_cleaned['sentence'] = df_cleaned.apply(lambda x: upperIfNeeded(x['sentence']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00e9c53-c7ad-4fb8-9f30-72928800bc18",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b4cfa5-ec6e-479d-9c5c-5abf53462f9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Results\n",
    "<b>Note:</b> The error fixing above is not perfect and some errors are still present in the dataframe after performing these operations.\n",
    "Also, some errors are too random to match and search using a pattern, and are still present in the dataframe.\n",
    "<br>The output below shows the number of errors corrected for this volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3756e44c-58ed-4e7d-84ac-06bd48853bee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section identifiers': 528,\n",
       " 'EOL hyphenation': 1826,\n",
       " 'Approved phrases': 114,\n",
       " 'Act seperators': 4,\n",
       " 'Incorrect starting nums': 340,\n",
       " 'Session headers': 7}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errorsDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562628b-e9b8-45de-96a4-e173b34f1d0b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d79b30-66d7-4921-9d70-c628c5b79c7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## E. Character length\n",
    "Add the character length feature. This is added here because the lengths of the sentences might have changed during the cleaning process above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07cb8cab-8486-4ed6-9990-788324fe9fda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cleaned[\"length\"] = df_cleaned['sentence'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e029f7c3-9f96-4ec4-9023-0bc47e9608b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>start_page</th>\n",
       "      <th>end_page</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AN ACT TO GRANT TO THE CITY COUNCIL OF CHARLESTON AND ITS SUCCESSORS THE TITLE AND INTEREST OF THE STATE TO CERTAIN LANDS IN CHARLESTON COUNTY FOR THE PURPOSES OF A NAVAL STATION.</td>\n",
       "      <td>00035</td>\n",
       "      <td>00035</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Be it enacted by the General Assembly of the State of South Carolina : That the right, title and interest of the State to the following described tract or parcel of land and land covered with water situated in the County of Charleston in this State be, and the same is hereby granted and ceded to “All that the City Council of Charleston and its successors: tract or parcel of land and land covered with water situate lying and being on the west bank of the Cooper River, in the County of Charleston in this State; measuring and containing seven hundred and sixty acres more or less, butting and bounding to the North by lands of Mrs. W. W. Lawton and by the Cooper River, on the East by Cooper River, on the South by Ship Yard Creek and on the West by Ship Yard Creek, as is delineated on a map of the city of Charleston and vicinity made by J. H. Dingle, City Surveyor, December 1900.”</td>\n",
       "      <td>00035</td>\n",
       "      <td>00036</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The grant herein made is upon the express condition that the City Council of Charleston shall convey, in fee simple to the United States of America, the said tract or parcel of land hereinbefore referred to in Section 1 of this Act for the site, location and purposes of a naval station.</td>\n",
       "      <td>00036</td>\n",
       "      <td>00036</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c. 3.</td>\n",
       "      <td>00036</td>\n",
       "      <td>00036</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That in case of the failure of the United States of America to locate, build or construct a Naval Station in the County of Charleston within the space of three years from the passage of this Act, then the title to said tract or parcel of land shall revert to the State.</td>\n",
       "      <td>00036</td>\n",
       "      <td>00036</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   sentence  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       AN ACT TO GRANT TO THE CITY COUNCIL OF CHARLESTON AND ITS SUCCESSORS THE TITLE AND INTEREST OF THE STATE TO CERTAIN LANDS IN CHARLESTON COUNTY FOR THE PURPOSES OF A NAVAL STATION.   \n",
       "1  Be it enacted by the General Assembly of the State of South Carolina : That the right, title and interest of the State to the following described tract or parcel of land and land covered with water situated in the County of Charleston in this State be, and the same is hereby granted and ceded to “All that the City Council of Charleston and its successors: tract or parcel of land and land covered with water situate lying and being on the west bank of the Cooper River, in the County of Charleston in this State; measuring and containing seven hundred and sixty acres more or less, butting and bounding to the North by lands of Mrs. W. W. Lawton and by the Cooper River, on the East by Cooper River, on the South by Ship Yard Creek and on the West by Ship Yard Creek, as is delineated on a map of the city of Charleston and vicinity made by J. H. Dingle, City Surveyor, December 1900.”    \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The grant herein made is upon the express condition that the City Council of Charleston shall convey, in fee simple to the United States of America, the said tract or parcel of land hereinbefore referred to in Section 1 of this Act for the site, location and purposes of a naval station.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     c. 3.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             That in case of the failure of the United States of America to locate, build or construct a Naval Station in the County of Charleston within the space of three years from the passage of this Act, then the title to said tract or parcel of land shall revert to the State.   \n",
       "\n",
       "  start_page end_page  length  \n",
       "0      00035    00035     179  \n",
       "1      00035    00036     888  \n",
       "2      00036    00036     287  \n",
       "3      00036    00036       5  \n",
       "4      00036    00036     269  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3842ee-eacf-4733-bd3b-bd643ac51aa3",
   "metadata": {},
   "source": [
    "Get rid of sentences with a low number of characters as they might not form meaningful sentences.\n",
    "<br>However, first, get the statistics on the length column to avoid removing meaningful sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58942c5-0a8d-4e8a-8d83-03cb8e35307c",
   "metadata": {},
   "source": [
    "<br>\n",
    "Define a cutoff for the sentences. All sentences belows this length will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa4ac75b-a0ab-4f3c-8bec-29d30ab37422",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_len = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7839e2ad-adaf-4e62-abba-33e865150dee",
   "metadata": {},
   "source": [
    "Create a smaller dataframe, and export it to csv, that only contains the short length sentences.\n",
    "Check the csv and change the length condition accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df695759-1e0d-4d5c-abfc-b81b5d4f02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_df = df[df['length'] < cut_len]\n",
    "# testing_df = testing_df.sort_values(by=['length'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6f93e92-774c-4d38-9ffb-58ec32df25d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b819d125-4444-42c0-8d7d-89a541bff83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment the following line of code to create the csv which contains the short length sentences.\n",
    "# testing_df.to_csv(f\"{year}_len_{cut_len}_testing.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3975324d-0032-444c-add6-d9de57f6c5bf",
   "metadata": {},
   "source": [
    "<br>\n",
    "Once, the length is decided, update the dataframe with sentences greater that the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51242400-c0db-421f-9d2e-fe40594a09f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial length\n",
    "ilen = df_cleaned.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05db1f3f-7454-4e23-819f-698c536bb277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the cleaned dataframe:  1359\n",
      "Reduction of about 26.82%\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df_cleaned[ df_cleaned[\"length\"] > cut_len]\n",
    "print(\"Length of the cleaned dataframe: \", df_cleaned.shape[0])\n",
    "print(\"Reduction of about {:.2f}%\".format( (1 - df_cleaned.shape[0]/ilen) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "51144099-ae02-4949-849c-48e5b271ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "df_cleaned.index.name = \"index\"\n",
    "\n",
    "# Rearrange columns\n",
    "cols = df_cleaned.columns.tolist()\n",
    "cols = [cols[0]] + cols[-1:] + cols[1:-1]\n",
    "df_cleaned = df_cleaned[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5774e28f-3bfd-41e2-b36b-aa701e0eecce",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f0294a-e3cf-47b2-919d-a49330d36996",
   "metadata": {
    "tags": []
   },
   "source": [
    "## F. Adding features\n",
    "The features added below are:\n",
    "- an id: a concatenation of the year and index number\n",
    "- whether the sentence is an Act or a Joint\n",
    "- the state that the law originates from"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de16ac6-8fd9-464f-8172-922fed2d50e0",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d5896-09bc-4db1-86ae-8f583d16431e",
   "metadata": {},
   "source": [
    "### 1. Adding ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1f9ed736-fffa-4c51-863a-ad181411e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPrefix(fileName: str, nameLen: int) -> str:\n",
    "    '''\n",
    "    Since the fileNames from the excel parsing could be any of any length\n",
    "    (ranging from 1-3), this function appends a string of 0's to the \n",
    "    start of the input so that it is the specified nameLen lengths long.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fileName : str\n",
    "        The file name that needs to be prefixed\n",
    "        The fileName shouldn't have a prefix, such as '.tiff'\n",
    "    nameLen : int\n",
    "        The length of the expected name of the file\n",
    "        Ex. '00034.jpg' would have length of 5\n",
    "        so nameLen should be 5\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A length nameLen file name (prefixed with 0's)\n",
    "    '''\n",
    "    \n",
    "    # prefix_length = nameLen - len(fileName)\n",
    "    prefix = \"0\" * (nameLen - len(fileName))\n",
    "    \n",
    "    return prefix + fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1801592f-d1d4-4908-b565-3d23737fca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.reset_index(inplace=True)\n",
    "df_cleaned.rename(columns={\"index\" : \"id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19ddb418-0773-42f7-8d58-1afa115d1891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The length of the id of the last row in the dataframe, which is used to assess how many 0's will be prefixed to the other ids\n",
    "maxNumLength = len(str(df_cleaned.last_valid_index()))\n",
    "\n",
    "df_cleaned['id'] = df_cleaned.apply(lambda x: str(year) + \"_\" + addPrefix( str(x['id']), maxNumLength ), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80060194-c068-4235-9b6c-cae29806afd0",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e4cdda-7013-42b3-9a9b-166f0c5ccc0b",
   "metadata": {},
   "source": [
    "### 2. Adding the remaining identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38bb6961-6e94-400c-b5b6-5a9621a68af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.insert(1, 'law_type', 'Acts')\n",
    "df_cleaned.insert(2, 'state', 'SOUTH CAROLINA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ec8e1-d79e-4467-86e1-4fb1293d8360",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b23a33-3387-4c9e-878e-3d3bf6e218dd",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fbcac79e-856a-449e-bffb-c80e72d9fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export the final dataframe to csv for viewing\n",
    "# df_cleaned.to_csv(f\"{year}_faster.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
